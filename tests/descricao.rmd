---
title: "Ajustando um modelo ARIMA no R"
output:
  html_notebook:
    toc: true
    toc_float: true
    toc_collapsed: true
    code_folding: show
    #toc_depth: 3
    theme: lumen

author: Michel Metran
number_sections: true
date: "`r format (Sys.time(), format='%Y-%m-%d %H:%M:%S %z')`"
---

<br>


## Ajuste da Tabela

Tenho uma tabela com todos os focos!
Preciso ler a tabela e agrupar os focos por mês!



```{r}
getwd()
```


```{r}

```









Segui as informações do vídeo [Ajustando um modelo ARIMA no R](https://www.youtube.com/watch?v=Txuo9JQjnKE).
No canal [StatiR](https://www.youtube.com/c/StatiR_br/videos) parece ter coisas relevantes!

Inicialmente carregamos as bibliotecas necessárias.

```{r}
library(forecast)
library(lmtest)
```

<br>

### Dados

Carregamos a base de dados que já vem nos pacotes, para fins de exemplo.
Trata-se de uma base de dados do número de passageiros por mês numa determinada companhia aérea.

```{r}
AirPassengers
```

Contudo, iremos converter a base para um formato vetorial, e posteriormente voltar para formato de *time series* para podermos compreender como iniciar com uma base de dados que estará, provavelmente, num formato tabular simples.

```{r}
v <- as.numeric(AirPassengers)
v
```


Retornando para o formato *time-series*

```{r}
z <- ts(
  v,
  frequency = 12,
  start = c(1949, 1),
)
z
```


<br>

### Gráficos

E agora podemos ver a série temporal

```{r}
ts.plot(z)
```

Podemos também ver o *seasonplot*, ou seja, o gráfico que mostra a tendência dos meses.

```{r}
seasonplot(
  z,
  col=rainbow(12),
  year.labels=TRUE,
  type='o',
  pch=16
)
```

Outro gráfico interessante, que além de mostrar a série temporal, apresenta os correlogramas de ACF e PACF.

```{r}
ggtsdisplay(z)
```

<br>

### Transformação

Define-se o valor de *lambda*.

```{r}
lbd <- BoxCox.lambda(z)
lbd
```

Aplica-se o valor de *lambda* na série.

```{r}
z_bc <- BoxCox(z, lambda = lbd)
z_bc
```

<br>

### Diferenciação

Deixar a série estacionária!
Primeiro descobrimos o melhor *lag* entre a série e aplicamos isso a série.

```{r}
# Descobrir
n_dif <- ndiffs(z_bc)
print(n_dif)

# Aplicar
z_bc_ndiff <- diff(z_bc, n_dif)
ggtsdisplay(z_bc_ndiff)
```


Interessante testar, APENAS PARA FINS DIDÁTICOS, como seria o plot da série com a diferenciação pelo *lag*, porém sem a transformação de BoxCox.

```{r}
z_ndiff <- diff(z, n_dif)
ggtsdisplay(z_ndiff)
```

<br>

### Diferenciação Sazonal

Primeiro descobrimos o melhor *lag* entre a série e aplicamos isso a série.

```{r}
# Descobrir
n_dif <- ndiffs(z_bc)
print(n_dif)

# Descobrir
ns_dif <- nsdiffs(z_bc_ndiff)
print(ns_dif)
```


#TODO: estudar questões abaixo!
Mesmo a função *nsdiffs* retornando o valor de 1, o vídeo indica ser correto inserir o parâmetro 12?? Porque?!
Além disso, aplica-se a *diferenciação sazonal* na série temporal que já passou por *diferenciação* (padrão)???


```{r}
# Aplicar
z_bc_nsdiff <- diff(z_bc_ndiff, 12)
ggtsdisplay(z_bc_nsdiff)
```

<br>

### Particionar a Série Temporal

Para testar o nível de acurácia do modelo, a série temporal é dividida!
Dessa forma torna-se possível obter um segmento da série e testar com o modelo definido, e prever como o modelo ajustado avaliará o outro trecho.

A partir disso é possível avaliar como o modelo fará as previsões futuras que desejamos!!, ajustar e obter parâmetros a serem aplicados no refit do modelo!

```{r}
z_treino <- ts(v[0:100], frequency = 12)
z_validacao <- ts(v[101:144], frequency = 12)
```



```{r}
fit <- Arima(
  y=z_treino,
  order = c(1,1,0),  # Ordem dos fatores: 1. Componente autoregressiva, 2. Uma diferenciação, 3, Componentes de Médias Móveis Sazonais.
  seasonal = c(1,1,0),
  lambda =  TRUE,  # O ARIMA já faz o BoxCox para ajustar o modelo!!!!
  #xreg =  df, usado para quando existem outras variáveis que explicam a série temporal!
)

summary(fit)
```

Para interpretarmos os resultados acima, temos que:
- Componente autoregressiva: -0.2434
- Componente autoregressiva sazonal: -0.2434
- Erro padrão 0.1046   0.1072
- *p-value*: será calculado posteriormente!, visto que summary não apresenta!


Para calcular o *p-value*
```{r}
coeftest(fit)
```

Temos que os dois valores são significativos (*).
Agora vamos plotar o gráfico! E, em vermelho, destacar os valores previstos que o modelo previu!
```{r}
plot(z_treino)
lines(fit$fitted, col = 'red')
```

<br>

### Acurácia

Interessante calcular algum parâmetro de acurácia entre o "real" e o "previsto!"

```{r}
accuracy(z_treino, fit$fitted)
```

Parâmetros relevantes:
- MAE: Erro médio Absoluto
- MAPE:

Uma vez com o modelo, é possível fazer previsões futuras!

```{r}
predi <- forecast(fit, h=44)
plot(predi)
```


```{r}
plot(as.numeric(z_validacao), type = 'l')
lines(as.numeric(predi$mean), col= 'blue')
```

Avaliar a acurácia!
O modelo erro, em média, 5,02% (MAPE) quando comparando:
valores que não participaram da elaboração do modelo (*z_validacao*) *versus* valores previstos no modelo!

```{r}
accuracy(as.numeric(z_validacao), as.numeric(predi$mean))
```

<br>

### Diagnóstico de Resíduos!

É possível observar no primeiro quadro que não há correlação entre os resíduos, o que é o que queremos (correlação deve existir apenas na série temporal!)!!!

Possível observar também a avaliação do p-value em cada *lag*! E vemos que até o *lag* não havia p-value singificante para a correlação de resíduos!!!

```{r}
tsdiag(fit)
```



```{r}
qqnorm(fit$residuals)
qqline(fit$residuals)
```






